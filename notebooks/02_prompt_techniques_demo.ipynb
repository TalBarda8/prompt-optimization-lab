{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Techniques Demonstration\n",
    "\n",
    "This notebook demonstrates all 7 prompt optimization techniques.\n",
    "\n",
    "**Techniques:**\n",
    "1. Baseline (direct questioning)\n",
    "2. Chain-of-Thought (CoT)\n",
    "3. Chain-of-Thought++ (CoT++)\n",
    "4. ReAct (Reasoning + Acting)\n",
    "5. Tree-of-Thoughts (ToT)\n",
    "6. Role-Based Prompting\n",
    "7. Few-Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
    "\n",
    "from prompts import (\n",
    "    BaselinePrompt,\n",
    "    ChainOfThoughtPrompt,\n",
    "    ChainOfThoughtPlusPlusPrompt,\n",
    "    ReActPrompt,\n",
    "    TreeOfThoughtsPrompt,\n",
    "    RoleBasedPrompt,\n",
    "    FewShotPrompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example question\n",
    "question = \"A store offers a 20% discount on an item originally priced at $150. If sales tax is 8%, what is the final price?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Baseline Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = BaselinePrompt().build()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"BASELINE PROMPT\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nSystem Prompt:\")\n",
    "print(baseline.system_prompt or \"(None)\")\n",
    "print(\"\\nUser Prompt:\")\n",
    "print(baseline.format(question=question))\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chain-of-Thought (CoT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cot = ChainOfThoughtPrompt().build()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"CHAIN-OF-THOUGHT PROMPT\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nSystem Prompt:\")\n",
    "print(cot.system_prompt)\n",
    "print(\"\\nUser Prompt:\")\n",
    "print(cot.format(question=question))\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Chain-of-Thought++ (CoT++)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_pp = ChainOfThoughtPlusPlusPrompt().build()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"CHAIN-OF-THOUGHT++ PROMPT\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nSystem Prompt:\")\n",
    "print(cot_pp.system_prompt)\n",
    "print(\"\\nUser Prompt:\")\n",
    "print(cot_pp.format(question=question))\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ReAct (Reasoning + Acting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "react = ReActPrompt().build()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"REACT PROMPT\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nSystem Prompt:\")\n",
    "print(react.system_prompt)\n",
    "print(\"\\nUser Prompt:\")\n",
    "print(react.format(question=question))\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tree-of-Thoughts (ToT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = TreeOfThoughtsPrompt().build()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TREE-OF-THOUGHTS PROMPT\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nSystem Prompt:\")\n",
    "print(tot.system_prompt)\n",
    "print(\"\\nUser Prompt:\")\n",
    "print(tot.format(question=question))\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Role-Based Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different roles\n",
    "roles = ['expert', 'teacher', 'scientist', 'mathematician']\n",
    "\n",
    "for role in roles:\n",
    "    role_prompt = RoleBasedPrompt(role=role).build()\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(f\"ROLE-BASED PROMPT: {role.upper()}\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\\nSystem Prompt:\")\n",
    "    print(role_prompt.system_prompt)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Few-Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define examples\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What is 15% of 200?\",\n",
    "        \"answer\": \"15% of 200 is 30. Calculation: 200 ร 0.15 = 30\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"If an item costs $80 after a 20% discount, what was the original price?\",\n",
    "        \"answer\": \"The original price was $100. Calculation: If 80% = $80, then 100% = $80 รท 0.8 = $100\"\n",
    "    },\n",
    "]\n",
    "\n",
    "few_shot = FewShotPrompt(examples=examples).build()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"FEW-SHOT LEARNING PROMPT\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nSystem Prompt:\")\n",
    "print(few_shot.system_prompt)\n",
    "print(\"\\nUser Prompt:\")\n",
    "print(few_shot.format(question=question))\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison Summary\n",
    "\n",
    "| Technique | Key Feature | Complexity | Use Case |\n",
    "|-----------|-------------|------------|----------|\n",
    "| Baseline | Direct question | Low | Simple factual queries |\n",
    "| CoT | Step-by-step reasoning | Medium | Math, logic problems |\n",
    "| CoT++ | CoT + verification | High | Complex calculations |\n",
    "| ReAct | Reasoning + actions | High | Multi-step decisions |\n",
    "| ToT | Multiple paths | Very High | Strategic planning |\n",
    "| Role-Based | Expert persona | Low | Domain-specific tasks |\n",
    "| Few-Shot | Learning from examples | Medium | Pattern recognition |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
