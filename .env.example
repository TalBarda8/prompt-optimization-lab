# Prompt Optimization & Evaluation System - Environment Variables
# Copy this file to .env and fill in your actual values

# LLM API Configuration
# Choose ONE provider and provide the corresponding API key

# OpenAI (for GPT-4)
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_ORG_ID=  # Optional: your organization ID

# Anthropic (for Claude 3.5 Sonnet)
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here

# Default LLM Provider
# Options: "openai" or "anthropic"
LLM_PROVIDER=openai

# Model Selection
# For OpenAI: "gpt-4", "gpt-4-turbo", "gpt-3.5-turbo"
# For Anthropic: "claude-3-5-sonnet-20241022", "claude-3-opus-20240229"
LLM_MODEL=gpt-4

# Pipeline Configuration
CONFIG_PATH=config/pipeline_config.yaml

# Caching
ENABLE_CACHE=true
CACHE_DIR=cache

# Rate Limiting
RATE_LIMIT_RPM=60  # Requests per minute
RATE_LIMIT_DELAY=1.0  # Seconds between requests

# Logging
LOG_LEVEL=INFO  # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_FILE=logs/pipeline.log

# Results
RESULTS_DIR=results
FIGURES_DIR=figures

# Random Seed (for reproducibility)
RANDOM_SEED=42

# Experimental Options
SKIP_BASELINE=false
SKIP_OPTIMIZATION=false
SKIP_VISUALIZATION=false
DRY_RUN=false  # If true, simulates without making API calls
